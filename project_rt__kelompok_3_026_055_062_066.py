# -*- coding: utf-8 -*-
"""PROJECT_RT_ KELOMPOK 3_026_055_062_066.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Bd_LZfPDZ_9qLXWUWn7YpxzB2PhCC39

# **Import Libraries**
"""

from random import random
from random import randint
from random import seed
import numpy as np
from numpy import arange
from numpy import mean
from numpy import std
from numpy import absolute
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import math as m
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.stattools import durbin_watson
from statsmodels.graphics.tsaplots import plot_acf
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import RANSACRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from scipy import stats
from scipy.stats import kstest
from sklearn.datasets import make_regression
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from matplotlib import pyplot
import warnings
warnings.filterwarnings('ignore')

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

"""# **Import Data**"""

df = pd.read_excel('7_kejahatan.xlsx')
df.head()

#Pembuktian jumlah sampel dari data yang telah diimpor
df.shape

#Cek tipe data
df.dtypes

"""# **Data Prepocessing**

## Cek Tipe Data
"""

df_dtypes = pd.DataFrame({'Columns':df.columns})

lst_nilai = []
for i in df_dtypes['Columns']:
  lst_nilai.append(df[[i]].sample(1).values[[0]])

df_dtypes['Value'] = lst_nilai
df_dtypes['Data Types'] = df.dtypes.values

df_dtypes = df_dtypes.reset_index().drop(columns = ['index'])
df_dtypes

df.info()

df.describe()

df.duplicated().sum()

"""## Cek Missing Values"""

df.isnull().sum()

lst_missval = []

for i in df.isnull().sum():
  lst_missval.append((i / len(df) * 100))

df_missval = pd.DataFrame({'Column Name':df.columns,
                           'Missing Value Percentage (%)':np.round(lst_missval,2),
                           'Data Types':df.dtypes})

df_missval = df_missval.sort_values(by='Missing Value Percentage (%)',
                       ascending = False).reset_index().drop(columns = 'index')

df_missval

"""# **Exploratory Data Analysis**

## Menyajikan Secara Visual Hubungan Antar Variabel
"""

# Histogram
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))
kolom = ('kriminal','metro','sma','miskin','single')
axes = axes.flatten()
for i, col in enumerate(kolom):
  sns.histplot(df[col],
               color='blue', bins=10, edgecolor='white', linewidth=2,ax=axes[i])
  axes[i].set_title(f'Distribution of {col}')

for j in range(len(kolom), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# Scatter plot
plt.figure(figsize=(18, 5))

predictors = df.drop(columns=['kriminal']).columns
response = df['kriminal']

for i, col in enumerate(predictors):
    plt.subplot(1, len(predictors) , i+1)
    x = df[col]
    y = response
    plt.scatter(x, y, marker='o', color='blue', alpha=0.5)
    plt.title(f'{col} vs kriminal')
    plt.xlabel(col)
    plt.ylabel('kriminal')
    plt.tight_layout()

# Heatmap
corr = df.corr()
sns.heatmap(corr, annot=True,cmap="Blues",mask = np.triu(np.ones_like(corr, dtype=bool)))
plt.title('Korelasi antar Variabel', fontsize=10, pad=10)
plt.show()

# Density plot
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))
kolom = ('kriminal','metro','sma','miskin','single')
axes = axes.flatten()
for i, col in enumerate(kolom):
  sns.distplot(df[col], hist=False, kde=True,
               color = 'blue',ax=axes[i])
  axes[i].set_title(f'Distribution of {col}')

for j in range(len(kolom), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# Boxplot
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))
kolom = ('kriminal','metro','sma','miskin','single')
axes = axes.flatten()
for i, col in enumerate(kolom):
  sns.boxplot(df[col],color='blue',ax=axes[i],notch=True, showcaps=False,
    flierprops={"marker": "x"},
    medianprops={"color": "black", "linewidth": 2})
  axes[i].set_title(f'Distribution of {col}')

for j in range(len(kolom), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""# **Analisis Deskriptif**

"""

def statistika_deskriptif(data):
    # Mendapatkan hanya kolom-kolom numerik
    kolom_numerik = data.select_dtypes(include=[np.number])

    # Inisialisasi vektor kosong untuk menyimpan hasil perhitungan
    variables = kolom_numerik.columns
    means, medians, q1s, q3s, variances, sds, ranges, sums, mins, maxs = ([] for _ in range(10))

    # Loop untuk setiap variabel numerik
    for variable in variables:
        values = kolom_numerik[variable]

        # Hitung statistika deskriptif
        means.append(np.mean(values))
        medians.append(np.median(values))
        q1s.append(np.percentile(values, 25))
        q3s.append(np.percentile(values, 75))
        variances.append(np.var(values))
        sds.append(np.std(values))
        ranges.append(np.max(values) - np.min(values))
        sums.append(np.sum(values))
        mins.append(np.min(values))
        maxs.append(np.max(values))

    hasil = pd.DataFrame({
        'Variabel': variables,
        'Mean': means,
        'Median': medians,
        'Q1': q1s,
        'Q3': q3s,
        'Variance': variances,
        'SD': sds,
        'Range': ranges,
        'Sum': sums,
        'Min': mins,
        'Max': maxs
    })

    return hasil

statistika_deskriptif(df)

"""# **Analisis Regresi**"""

#Membuat variabel sebelum dilakukan perhitungan model regresi
x = df.drop(columns=['kriminal'])
y = df['kriminal']

X = sm.add_constant(x)
print(X)

"""## Ordinary Least Squares Regression"""

#OLS Model
result_ols = sm.OLS(y, x).fit()
# Melatih model
print(result_ols.summary())

y_pred = result_ols.predict(x)

# Menghitung RMSE
rmse_ols = np.sqrt(mean_squared_error(y, y_pred))

# Menampilkan RMSE
print("Root Mean Squared Error (RMSE):", rmse_ols)

"""Persamaan ***OLS Regression*** dari output tersebut adalah:

kriminal = -2060.9260 + 8.0019 (metro) + 4.6349 (sma) + 22.9626 (miskin) + 128.3664 (single)

Keterangan:

- variabel dependen : kriminal (kejahatan kekerasan per 100.000 orang)
- variabel independen : metro (persentase penduduk yang tinggal di wilayah metropolitan), sma (persentase penduduk yang berpendidikan sekolah menengah atas ke atas), miskin (persentase penduduk yang hidup di bawah garis kemiskinan), dan single (persentase penduduk yang merupakan orang tua tunggal)

## Robust Regression
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.linear_model import RANSACRegressor

# Fitur robust regression dengan metode RANSAC
model_robust = RANSACRegressor(random_state=0)

# Melatih model pada set pelatihan
result_robust = model_robust.fit(X, y)

# Membuat prediksi pada set pengujian
y_pred_robust = model_robust.predict(X)

# Menampilkan koefisien dan intercept
print("Coefficients:", model_robust.estimator_.coef_)
print("Intercept:", model_robust.estimator_.intercept_)

# Menghitung dan menampilkan metrik R2
r2_robust = r2_score(y, y_pred_robust)
print("R^2 Score:", r2_robust)

# Menghitung adjusted R-squared
n = len(y)
k = X.shape[1]
adjusted_r2_robust = 1 - ((1 - r2_robust) * (n - 1) / (n - k - 1))

# Menampilkan adjusted R-squared
print("Adjusted R^2 Score:", adjusted_r2_robust)

# Menghitung dan menampilkan RMSE
rmse_robust = mean_squared_error(y, y_pred_robust, squared=False)
print("Root Mean Squared Error (RMSE):", rmse_robust)

"""Persamaan ***Robust Regression*** dari output tersebut adalah:

kriminal = -984.5609 + 5.9841 (metro) - 9.5955(sma) + 16.5958 (miskin) + 153.5013 (single)

Keterangan:

- variabel dependen : kriminal (kejahatan kekerasan per 100.000 orang)
- variabel independen : metro (persentase penduduk yang tinggal di wilayah metropolitan), sma (persentase penduduk yang berpendidikan sekolah menengah atas ke atas), miskin (persentase penduduk yang hidup di bawah garis kemiskinan), dan single (persentase penduduk yang merupakan orang tua tunggal)

## Uji Signifikansi Parameter

### Uji Serentak

$H_{0}: \beta_{1} = \beta_{2} = \beta_{3} = \beta_{4} = 0$

$H_{1}$: minimal ada satu $\beta_{i}  \neq 0$, $i=1,2,3,4$
"""

df_simultan = pd.DataFrame({'F-hitung':[result_ols.fvalue],
                                  'p-value':[result_ols.f_pvalue],
                                  'alpha':[0.05]})

df_simultan['Kesimpulan'] = df_simultan['p-value'].gt((df_simultan['alpha']))
df_simultan['Kesimpulan'] = df_simultan['Kesimpulan'].replace({True:'Gagal Tolak H0',
                                                                           False:'Tolak H0'})

df_simultan

"""Kesimpulan:

Tolak H0, variabel independen x berpengaruh terhadap variabel dependen y

### Uji Parsial

Untuk $\beta_{1}$

$H_{0}: \beta_{1} = 0$

$H_{1}: \beta_{1} \neq 0$

Untuk $\beta_{2}$

$H_{0}: \beta_{2} = 0$

$H_{1}: \beta_{2} \neq 0$

Untuk $\beta_{3}$

$H_{0}: \beta_{3} = 0$

$H_{1}: \beta_{3} \neq 0$

Untuk $\beta_{4}$

$H_{0}: \beta_{4} = 0$

$H_{1}: \beta_{4} \neq 0$
"""

df_partial = pd.DataFrame()
df_partial['Variabel'] = result_ols.tvalues.index
df_partial['t-hitung'] = result_ols.tvalues.values
df_partial['p-value'] = result_ols.pvalues.values
df_partial['alpha'] = 0.05

df_partial['Kesimpulan'] = df_partial['p-value'].gt((df_partial['alpha']))
df_partial['Kesimpulan'] = df_partial['Kesimpulan'].replace({True:'Gagal Tolak H0',
                                                                           False:'Tolak H0'})

df_partial

"""Kesimpulan:

- metro :  Mengalami Tolak H0, yang artinya persentase penduduk yang tinggal di wilayah metropolitan berpengaruh terhadap tindak kriminal yang ada

- sma : Mengalami Gagal Tolak H0, yang artinya persentase penduduk yang masih sma tidak berpengaruh terhadap tindak kriminal yang ada

- miskin : Mengalami Gagal Tolak H0, yang artinya persentase penduduk yang hidup di bawah garis kemiskinan tidak berpengaruh terhadap tindak kriminal yang ada

- single : Mengalami Tolak H0, yang artinya persentase penduduk yang merupakan orang tua tunggal berpengaruh terhadap tindak kriminal yang ada

# **Model Regresi (R^2 dan R^2 Adjusted)**

## Ordinary Least Squares Regression
"""

df_model_evaluation = pd.DataFrame({'Model':['Ordinary Least Squares Regression'],
                                    'R-Square':[result_ols.rsquared],
                                    'Adjusted R-Square':[result_ols.rsquared_adj],
                                    'RMSE':[rmse_ols]})

df_model_evaluation

"""Berikut adalah interpretasi dari output tersebut:
- Model ***OLS Regression*** memiliki R-Square sebesar 0.841, yang menunjukkan bahwa model mampu menjelaskan sekitar 84,1% dari variasi dalam variabel target (kriminal).

- Model ***OLS Regression*** memiliki Adjusted R-Square sebesar 0.827, yang menunjukkan bahwa model mampu menjelaskan sekitar 82,7% dari variasi dalam variabel target setelah mempertimbangkan jumlah variabel independen yang digunakan dalam model.

- Model ***OLS Regression*** memiliki RMSE sekitar 174 menunjukkan bahwa rata-rata kesalahan prediksi model ini sekitar 174 unit dari nilai aktual.

Secara keseluruhan, kedua model menunjukkan kinerja yang baik dalam menjelaskan hubungan antara variabel independen dengan variabel dependen.

## Robust Regression
"""

df_model_evaluation = pd.DataFrame({'Model':['Robust Regression'],
                                    'R-Square':[r2_robust],
                                    'Adjusted R-Square':[adjusted_r2_robust],
                                    'RMSE':[rmse_robust]})

df_model_evaluation

"""Berikut adalah interpretasi dari output tersebut:
- Model ***Robust Regression*** memiliki R-Square sebesar 0.791, yang menunjukkan bahwa model mampu menjelaskan sekitar 79,1% dari variasi dalam variabel target (kriminal).

- Model ***Robust Regression*** memiliki Adjusted R-Square sebesar 0.799, yang menunjukkan bahwa model mampu menjelaskan sekitar 79,9% dari variasi dalam variabel target setelah mempertimbangkan jumlah variabel independen yang digunakan dalam model.

- Model ***Robust Regression*** memiliki RMSE sekitar 200 menunjukkan bahwa rata-rata kesalahan prediksi model ini sekitar 200 unit dari nilai aktual.

Secara keseluruhan, kedua model menunjukkan kinerja yang baik dalam menjelaskan hubungan antara variabel independen dengan variabel dependen.

# **Uji Asumsi Error**

## Normalitas
"""

from scipy.stats import kstest
residuals = result_ols.resid
# uji normalitas dengan kolmogorov-smirnov test
ks_statistic, ks_p_value = kstest(residuals, 'norm', args=(np.mean(residuals), np.std(residuals)))

print('Statistic KS:', ks_statistic)
print('P-value:', ks_p_value)

# interpret
alpha = 0.05
if ks_p_value > alpha:
	print('Data Berdistribusi Normal (Gagal Tolak H0)')
else:
	print('Data Tidak Berdistribusi Normal (Tolak H0)')

# Visualisasi
sns.distplot(residuals, hist=True, kde=True,
             color = 'blue',
             hist_kws={'edgecolor':'white'},
             kde_kws={'linewidth': 2})

import matplotlib.pyplot as plt
import scipy.stats as stats

# Assuming you have 'residuals' defined

# Create a Q-Q plot
stats.probplot(residuals, dist="norm", plot=plt)

# Get the current axes
ax = plt.gca()

# Get the line from the Q-Q plot
line = ax.get_lines()[0]

# Change the color of the markers
line.set_markerfacecolor('blue')
line.set_markeredgecolor('blue')

plt.show()

"""## Autokorelasi"""

import pandas as pd
import statsmodels.api as sm

df_autokorelasi = pd.read_excel("/content/7_kejahatan.xlsx")

# Inisiasi Variabel
y_autokorelasi = df_autokorelasi['kriminal']
X_autokorelasi = df_autokorelasi[['metro', 'sma', 'miskin', 'single']]
X_autokorelasi = sm.add_constant(X_autokorelasi)

# Model Regresi
model_autokorelasi = sm.OLS(y_autokorelasi, X_autokorelasi).fit()

# Residuals
residuals_autokorelasi = model_autokorelasi.resid

# Nilai Durbin-Watson
dw_test_autokorelasi = sm.stats.stattools.durbin_watson(residuals_autokorelasi)
print(f'Hasil hitung Statistik Durbin-Watson: {dw_test_autokorelasi}')

# Batas
N_autokorelasi = len(residuals_autokorelasi)
k_autokorelasi = X_autokorelasi.shape[1] - 1  # Jumlah variabel independen

dU_autokorelasi = 1.7218
dL_autokorelasi = 1.3855

print(f'dU = {dU_autokorelasi}')
print(f'dL = {dL_autokorelasi}')
print()

# Interpretasi
if dw_test_autokorelasi < dL_autokorelasi:
    print(f'Terdapat indikasi autokorelasi positif. DW < dL ({dw_test_autokorelasi} < {dL_autokorelasi}). Perlu diteliti lebih lanjut untuk autokorelasi positif.')
elif dL_autokorelasi <= dw_test_autokorelasi <= dU_autokorelasi:
    print('Tidak dapat mengambil keputusan. dL <= DW <= dU')
    print(f'{dL_autokorelasi} <= {dw_test_autokorelasi} <= {dU_autokorelasi}')
elif dw_test_autokorelasi > 4 - dU_autokorelasi:
    print(f'Terdapat indikasi autokorelasi negatif. DW > 4 - dU ({dw_test_autokorelasi} > {4 - dU_autokorelasi}). Perlu diteliti lebih lanjut untuk autokorelasi negatif.')
else:
    print('Hasil tidak diketahui. Mohon periksa statistik Durbin-Watson dan nilai kritis.')

"""## Heterokedastisitas"""

# Uji statistik
# prediksi
pred_y = result_ols.predict(X)

# simpan residu
resid = y - pred_y

# absolut residu
y_abs_resid = np.abs(resid)

result_glejser = sm.OLS(y_abs_resid, x).fit()

df_glejser = pd.DataFrame(result_glejser.pvalues, columns = ['p-value'])
df_glejser['Keputusan'] = df_glejser['p-value'].gt(0.05)
df_glejser['Keputusan'] = df_glejser['Keputusan'].replace({True:'Gagal Tolak H0',
                                                           False:'Tolak H0'})
df_glejser

# Visualisasi
plt.scatter(x=result_ols.fittedvalues, y=residuals, color = 'blue')
plt.xlabel('fitted value', fontsize=10)
plt.ylabel('residuals', fontsize=10)
plt.show()

"""## Multikolinearitas"""

# VIF dataframe
vif_data = pd.DataFrame()
vif_data["feature"] = X.columns

# calculating VIF for each feature
vif_data["VIF"] = [variance_inflation_factor(X.values, i)
                          for i in range(len(X.columns))]
vif_data['keputusan'] = vif_data["VIF"].gt(10)
vif_data['keputusan'] = vif_data['keputusan'].replace({True:'Tolak H0',
                                                                           False:' Gagal Tolak H0'})

vif_data